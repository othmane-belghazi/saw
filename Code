from sklearn.linear_model import LogisticRegression
from interpret.glassbox import ExplainableBoostingClassifier
import numpy as np

# --- ÉTAPE 1 : Le Chef (GLM sur le Prix uniquement) ---
# On utilise le prix (et peut-être le prix au carré pour une courbe)
X_prix = df[['prix']] 

glm = LogisticRegression(penalty=None) # Pas de régularisation pour laisser le prix jouer à fond
glm.fit(X_prix, y_train)

# On récupère le "Log-Odds" (le score brut, pas la probabilité %)
# C'est crucial : on veut le raw score pour l'init_score
glm_offset = glm.decision_function(X_prix)


# --- ÉTAPE 2 : L'Expert (EBM sur le reste) ---
# On prend toutes les variables SAUF le prix
X_profil = df[['capital_incendie', 'type_occupation', 'zone', ...]]

ebm = ExplainableBoostingClassifier()

# C'EST ICI LA MAGIE : on passe l'offset du GLM dans init_score
ebm.fit(X_profil, y_train, init_score=glm_offset)

# --- ÉTAPE 3 : Prédiction Finale ---
# Pour prédire, il faut sommer les deux :
# Score Final = Score(GLM Prix) + Score(EBM Profil)
# (La librairie gère souvent ça, mais conceptuellement c'est l'addition des deux)
