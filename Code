import pandas as pd
import numpy as np
from ortools.linear_solver import pywraplp
import matplotlib.pyplot as plt
import seaborn as sns

# ==============================================================================
# 1. CONFIGURATION ET CHARGEMENT (Simulation des entrées)
# ==============================================================================

# -- MAPPING DES VARIABLES --
# Adapte ces noms si tes fichiers ont des noms différents
COL_PF_ID = 'Contrat'
COL_PF_PRIME_PURE = 'COPTTC'               # Numérateur ELR (Charge)
COL_PF_PRIME_COMM = 'tarif_vendu_ht_sansFR' # Dénominateur ELR (Prime)
COL_PF_ACT = 'Activite'

COL_DEV_ID = 'numcnt'
COL_DEV_PRIME = 'tarif_vendu_ht_sansFR'
COL_DEV_ACT = 'activite'

# Features attendues par ton modèle EBM (ordre strict)
FEATURES_EBM = [
    'tarif_vendu_ht_sansFR', 'activite', 'type_client', 'produit', 
    'surface_bins', 'chiffre_affaires_bins', 'type_occupation_local', 
    'cop_ttc', 'reduction', 'capital_incendie_bins'
]

# -- SIMULATION DES DONNÉES (À REMPLACER PAR TES IMPORTS) --
# Dans ton vrai script : df_pf = pd.read_csv(...) et df_devis = pd.read_csv(...)
np.random.seed(42)

# 1. Base Portefeuille (Historique)
activites_list = ['Bureau', 'Commerce', 'Restauration', 'BTP']
n_pf = 5000
df_pf = pd.DataFrame({
    COL_PF_ID: range(n_pf),
    COL_PF_ACT: np.random.choice(activites_list, n_pf),
    COL_PF_PRIME_COMM: np.random.uniform(1000, 3000, n_pf)
})
# Simulation ELR : Bureau (30%), Commerce (50%), Resto (70%), BTP (95%)
elr_map = {'Bureau': 0.30, 'Commerce': 0.50, 'Restauration': 0.70, 'BTP': 0.95}
df_pf[COL_PF_PRIME_PURE] = df_pf.apply(lambda x: x[COL_PF_PRIME_COMM] * elr_map[x[COL_PF_ACT]] * np.random.normal(1, 0.2), axis=1)

# 2. Base Devis (Cible 40k)
n_devis = 5000 # Réduit pour l'exemple, mets 40000
df_devis = pd.DataFrame({
    COL_DEV_ID: range(n_devis),
    COL_DEV_ACT: np.random.choice(activites_list, n_devis),
    COL_DEV_PRIME: np.random.uniform(1000, 3000, n_devis),
    # Autres colonnes bidons pour l'EBM
    'type_client': 'Pro', 'produit': 'MRP', 'surface_bins': '50-100',
    'chiffre_affaires_bins': '100k-500k', 'type_occupation_local': 'Locataire',
    'cop_ttc': 100, 'reduction': 0, 'capital_incendie_bins': '100k'
})

# 3. Mock Modèle EBM (À REMPLACER PAR TON MODEL.PREDICT_PROBA)
class MockEBM:
    def predict_proba(self, X):
        # Simule une proba décroissante avec le prix
        # X est un DataFrame
        base_proba = 0.35
        # Plus c'est cher, moins on convertit
        price_impact = -0.00005 * X[COL_DEV_PRIME] 
        return np.column_stack([np.zeros(len(X)), base_proba + price_impact])

ebm_model = MockEBM() 

print(">>> Données chargées et modèle prêt.")

# ==============================================================================
# 2. CALCULS ACTUARIELS (ELR & COÛT TECHNIQUE)
# ==============================================================================

# A. Calcul ELR Historique par Activité (Triage inclus pour la contrainte C3)
print(">>> Calcul des ELR par activité...")
stats_activites = df_pf.groupby(COL_PF_ACT).apply(
    lambda x: pd.Series({
        'elr': x[COL_PF_PRIME_PURE].sum() / x[COL_PF_PRIME_COMM].sum()
    })
).reset_index()

# B. Enrichissement des Devis
df_model = df_devis.merge(
    stats_activites, 
    left_on=COL_DEV_ACT, 
    right_on=COL_PF_ACT, 
    how='left'
)
# Coût Technique (Constante €) = Prime Actuelle * ELR Activité
df_model['cout_technique'] = df_model[COL_DEV_PRIME] * df_model['elr']

# C. Bornes de Majoration (Segmentation Métier)
conditions = [
    (df_model['elr'] < 0.30),
    (df_model['elr'] >= 0.30) & (df_model['elr'] < 0.50),
    (df_model['elr'] >= 0.50) & (df_model['elr'] < 0.80),
    (df_model['elr'] >= 0.80)
]
# Min et Max pour chaque segment
choices_min = [0.00,  0.005, 0.02, 0.05]
choices_max = [0.005, 0.01,  0.04, 0.10]

df_model['min_h'] = np.select(conditions, choices_min, default=0.05)
df_model['max_h'] = np.select(conditions, choices_max, default=0.10)

# ==============================================================================
# 3. GÉNÉRATION DES SCÉNARIOS & SCORING
# ==============================================================================
print(">>> Génération des scénarios (Discrétisation)...")

scenarios_list = []
ebm_inputs = []

# Paramètres de discrétisation
NB_STEPS = 20 # 20 scénarios par devis -> Précision fine

for idx, row in df_model.iterrows():
    steps = np.linspace(row['min_h'], row['max_h'], NB_STEPS)
    steps = np.unique(steps) # Évite doublons
    
    for hausse in steps:
        new_prime = row[COL_DEV_PRIME] * (1 + hausse)
        
        # Préparation input EBM
        feats = row[FEATURES_EBM].to_dict()
        feats[COL_DEV_PRIME] = new_prime # On met à jour le prix
        ebm_inputs.append(feats)
        
        scenarios_list.append({
            'devis_id': row[COL_DEV_ID],
            'activite': row[COL_DEV_ACT],
            'elr_segment': row['elr'],
            'prime_base': row[COL_DEV_PRIME],
            'hausse': hausse,
            'prime_finale': new_prime,
            'cout_technique': row['cout_technique']
        })

df_scen = pd.DataFrame(scenarios_list)

# Scoring en Batch (Très rapide)
print(">>> Scoring EBM en cours...")
df_ebm_input = pd.DataFrame(ebm_inputs)
probas_raw = ebm_model.predict_proba(df_ebm_input)[:, 1]

# Ajustement Expert (Si nécessaire pour forcer l'élasticité)
# Ex: on réduit la proba de 0.2% pour chaque 1% de hausse supplémentaire
df_scen['proba_predite'] = probas_raw * (1 - 0.2 * df_scen['hausse'])

# Calcul Marge Espérée (Objectif)
df_scen['marge_esperee'] = (df_scen['prime_finale'] - df_scen['cout_technique']) * df_scen['proba_predite']

# ==============================================================================
# 4. OPTIMISATION (MILP)
# ==============================================================================
print(f">>> Construction du modèle (Variables : {len(df_scen)})...")
solver = pywraplp.Solver.CreateSolver('SCIP')
solver.set_time_limit(180 * 1000) # 3 minutes max

# A. Variables Binaires
x = {i: solver.BoolVar(f'x_{i}') for i in df_scen.index}

# B. Contrainte Unicité (1 scénario par devis)
for d_id, group_idxs in df_scen.groupby('devis_id').groups.items():
    solver.Add(solver.Sum([x[i] for i in group_idxs]) == 1)

# C. Contrainte Rétention Volume Global (>= 90%)
# On estime le volume max potentiel (somme des max probas par devis)
vol_ref = df_scen.groupby('devis_id')['proba_predite'].max().sum()
current_vol = solver.Sum([row['proba_predite'] * x[i] for i, row in df_scen.iterrows()])
solver.Add(current_vol >= 0.90 * vol_ref)

# D. Contrainte MONOTONIE INTER-ACTIVITÉS (C3)
# 1. On trie les activités par ELR croissant
sorted_acts = stats_activites.sort_values('elr')[COL_PF_ACT].tolist()
print(f"Ordre Monotonie imposé : {' -> '.join(sorted_acts)}")

# 2. On prépare les Dénominateurs (Volumes Primes Fixes par Activité)
denoms = df_model.groupby(COL_DEV_ACT)[COL_DEV_PRIME].sum().to_dict()

# 3. On prépare les Numérateurs (Expressions Linéaires)
nums_expr = {}
for act in sorted_acts:
    # Indices des scénarios de cette activité
    idxs = df_scen[df_scen['activite'] == act].index
    # Somme (PrimeBase * Hausse * x)
    expr = solver.Sum([df_scen.loc[i, 'prime_base'] * df_scen.loc[i, 'hausse'] * x[i] for i in idxs])
    nums_expr[act] = expr

# 4. Création de la chaîne d'inégalités : Moyenne(A) <= Moyenne(B)
for i in range(len(sorted_acts) - 1):
    act_A = sorted_acts[i]
    act_B = sorted_acts[i+1]
    
    # Produit en croix : NumA * DenB <= NumB * DenA
    solver.Add(
        nums_expr[act_A] * denoms[act_B] <= nums_expr[act_B] * denoms[act_A]
    )

# E. Objectif : Maximiser la Marge Totale
objective = solver.Sum([row['marge_esperee'] * x[i] for i, row in df_scen.iterrows()])
solver.Maximize(objective)

# Résolution
print(">>> Résolution en cours...")
status = solver.Solve()

# ==============================================================================
# 5. RÉSULTATS & VISUALISATION
# ==============================================================================

if status in [pywraplp.Solver.OPTIMAL, pywraplp.Solver.FEASIBLE]:
    print(f"\n>>> SUCCÈS ({status}) ! Marge Espérée Totale : {solver.Objective().Value():,.0f} €")
    
    # Récupération des choix
    idx_opt = [i for i in x if x[i].solution_value() > 0.5]
    df_res = df_scen.loc[idx_opt].copy()
    
    # --- VISUALISATION 1 : La Preuve de Monotonie ---
    # On vérifie que la hausse moyenne suit bien l'ELR
    viz_df = df_res.groupby('activite').agg({
        'elr_segment': 'mean',
        'hausse': 'mean',
        'prime_base': 'sum' # Poids
    }).sort_values('elr_segment').reset_index()
    
    print("\n--- Tableau de Synthèse par Activité ---")
    print(viz_df[['activite', 'elr_segment', 'hausse']])
    
    plt.figure(figsize=(10, 6))
    sns.set_style("whitegrid")
    
    # Barplot combiné
    ax1 = sns.barplot(data=viz_df, x='activite', y='hausse', color='skyblue', alpha=0.6, label='Hausse Moyenne')
    ax2 = ax1.twinx()
    sns.lineplot(data=viz_df, x='activite', y='elr_segment', color='red', marker='o', lw=2, ax=ax2, label='ELR (Risque)')
    
    ax1.set_ylabel('Hausse Tarifaire (%)', color='blue')
    ax2.set_ylabel('ELR (%)', color='red')
    ax1.set_title('Validation de la Monotonie : La hausse suit le risque', fontsize=14)
    
    # Formatage %
    vals = ax1.get_yticks()
    ax1.set_yticklabels(['{:,.1%}'.format(x) for x in vals])
    vals2 = ax2.get_yticks()
    ax2.set_yticklabels(['{:,.0%}'.format(x) for x in vals2])
    
    plt.show()

    [Image of linear programming feasible region]
    
    # --- VISUALISATION 2 : Distribution des hausses ---
    plt.figure(figsize=(8, 5))
    sns.histplot(df_res['hausse'], bins=20, kde=True, color='green')
    plt.title('Distribution des Hausses appliquées', fontsize=14)
    plt.xlabel('Taux de Majoration')
    plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.1%}'.format(x)))
    plt.show()
    
else:
    print("Pas de solution trouvée. Vérifier les contraintes (ex: monotonie trop stricte si ELR très proches).")
